{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Show available files\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pandas","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load data\nin pandas data is represented ad dataframe(df). Dataframe is like tables or sheets in exel.\nReading csv data from file.","metadata":{}},{"cell_type":"code","source":"house_df = pd.read_csv('/kaggle/input/housing-prices-kaggle-learn-dataset/train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-06T17:50:08.949441Z","iopub.execute_input":"2023-11-06T17:50:08.949844Z","iopub.status.idle":"2023-11-06T17:50:08.994861Z","shell.execute_reply.started":"2023-11-06T17:50:08.949794Z","shell.execute_reply":"2023-11-06T17:50:08.993957Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Get number of rows and columns of a pandas dataframe or numpy array","metadata":{}},{"cell_type":"code","source":"house_df.shape # (rows, columns)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T17:50:10.849587Z","iopub.execute_input":"2023-11-06T17:50:10.849992Z","iopub.status.idle":"2023-11-06T17:50:10.857212Z","shell.execute_reply.started":"2023-11-06T17:50:10.849961Z","shell.execute_reply":"2023-11-06T17:50:10.856147Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(1460, 81)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Display data\n**describe()** method displays impoortant statistics about all the columns in the dataframe.\n\n**head()** method displays initial rows of the dataframe. Number of rows to be displayed can be specified as **head(number_of_rows)**","metadata":{}},{"cell_type":"code","source":"house_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"house_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Operations","metadata":{}},{"cell_type":"markdown","source":"**Select columns**","metadata":{}},{"cell_type":"code","source":"# single column\nsale_price=house_df[\"SalePrice\"]\nsale_price.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# multiple columns\nfeature_columns=[\"LotArea\",\"YearBuilt\",\"1stFlrSF\",\"2ndFlrSF\",\"FullBath\",\"BedroomAbvGr\",\"TotRmsAbvGrd\"]\nmultiple_columns=housing_df[feature_columns]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare training and testing data","metadata":{}},{"cell_type":"markdown","source":"Data is mainly divided in to 2 category, features data and target data.\n\n#### Features(**X**) and Target(**y**) columns\n**Features** are the data(columns) which the model will take as input and give the prediction as output.\n\n**Target** is the actual value that we want to predict. Target data is compared with the predictions made by the model and the model make adjustments to for better prediction.\n\n#### Training and testing(validation) dataset\nTraining data is used to train the model and testing data is used to test the accuracy of the model. Each dataset contains features and target columns.\nIf only one dataset is given, then we should divide it into 2 catagories of data, one for **Training** and one for **Validating**.\n\nBoth training and testing dataset contains set of features and target columns, denoted as **\"X_train, y_train, X_valid, y_valid\"**","metadata":{}},{"cell_type":"markdown","source":"### Preparing features and targets from training and testing datasets\n\nThere are multiple ways to do this.","metadata":{}},{"cell_type":"markdown","source":"1. **define feature columns and target column individually**\n\nwe can define specific columns that we want to use as features","metadata":{}},{"cell_type":"code","source":"feature_columns=[\"LotArea\",\"YearBuilt\",\"1stFlrSF\",\"2ndFlrSF\",\"FullBath\",\"BedroomAbvGr\",\"TotRmsAbvGrd\"]\ntarget_column='SalePrice'\n\nX_train=house_df[feature_columns]\ny_train=house_df[target_column]\n\nprint(f\"features:\\n {X_train.head(1)}\")\nprint(f\"target:\\n {train_y.head(1)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. **from the dataset, pop the target column and save to use as target column and the rest of the dataset will be used as features**\n\nIf all the columns of the dataset (except the target) will be used as features then this method is useful\n\n**IMPORTANT!** remember to remove any column from features dataset that is not necessary","metadata":{}},{"cell_type":"code","source":"y_train=house_df.pop('SalePrice')\nX_train=house_df\n\nprint(f\"features:\\n {X_train.head(1)}\")\nprint(f\"target:\\n {train_y.head(1)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3. **IMPORTANT!** **use scikit learn to divide training and testing data**\n\nIn most cases we want to divide the dataset in to part for training and testing for model validation. This is a efficient to do that.\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nfeature_columns=[\"LotArea\",\"YearBuilt\",\"1stFlrSF\",\"2ndFlrSF\",\"FullBath\",\"BedroomAbvGr\",\"TotRmsAbvGrd\"]\ntarget_column='SalePrice'\n\nX = house_df[feature_columns]\ny = house_df[target_column]\ntrain_X, val_X, train_y, val_y = train_test_split(X,y, random_state=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scikit learn","metadata":{}},{"cell_type":"markdown","source":"### Defining Models\n\nThere are many predefined models in scikit learn. Some of them are Decision tree, random forest\n\nFor model reproducibility, set a numeric value for random_state when specifying the model","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nhousing_model = DecisionTreeRegressor(random_state=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nhousing_model = RandomForestRegressor(random_state=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train models","metadata":{}},{"cell_type":"code","source":"housing_model.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T17:37:55.737201Z","iopub.execute_input":"2023-11-06T17:37:55.737591Z","iopub.status.idle":"2023-11-06T17:37:56.256535Z","shell.execute_reply.started":"2023-11-06T17:37:55.737564Z","shell.execute_reply":"2023-11-06T17:37:56.255369Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"RandomForestRegressor(random_state=1)","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=1)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Make prediction","metadata":{}},{"cell_type":"code","source":"prediction = housing_model.predict(X_test)\nprint(prediction[:5]) # prints first 5 predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Calculate error","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n\nmae = mean_absolute_error(y_test, prediction)\nprint(f\"mean absolute error on test data:{mae}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Nural network using Tensorflow and keras","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2023-11-07T07:03:32.805305Z","iopub.execute_input":"2023-11-07T07:03:32.805760Z","iopub.status.idle":"2023-11-07T07:03:44.053399Z","shell.execute_reply.started":"2023-11-07T07:03:32.805723Z","shell.execute_reply":"2023-11-07T07:03:44.052159Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**Tensor**: \n\nTensors are basically TensorFlow's version of a Numpy array with a few differences that make them better suited to deep learning. One of the most important is that tensors are compatible with GPU and TPU) accelerators. TPUs, in fact, are designed specifically for tensor computations. Internally, Keras represents the weights of a neural network with tensors.\n\n**Input shape**: \n\nInput shape is the number of feature columns. Keras represents weights as tensors, but also uses tensors to represent data. When you set the input_shape argument, you are telling Keras the dimensions of the array it should expect for each example in the training data. Setting input_shape=[3] would create a network accepting vectors of length 3, like [0.2, 0.4, 0.6]\n\nA \"layer\" in Keras is a very general kind of thing. A layer can be, essentially, any kind of data transformation. Many layers, like the convolutional and recurrent layers, transform data through use of neurons and differ primarily in the pattern of connections they form. Others though are used for feature engineering or just simple arithmetic. There's a whole world of layers to discover [-- check them out!](https://www.tensorflow.org/api_docs/python/tf/keras/layers)\n\n","metadata":{}},{"cell_type":"markdown","source":"### Single nuron","metadata":{}},{"cell_type":"code","source":"input_shape = [10]\nmodel = keras.Sequential([layers.Dense(units=1, input_shape=input_shape)])","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:10:52.283420Z","iopub.execute_input":"2023-11-06T18:10:52.284214Z","iopub.status.idle":"2023-11-06T18:10:52.437446Z","shell.execute_reply.started":"2023-11-06T18:10:52.284178Z","shell.execute_reply":"2023-11-06T18:10:52.436337Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Deep neural network\n\nNeural networks typically organize their neurons into layers. When we collect together linear units having a common set of inputs we get a dense layer.\n\nThere is a whole family of variants of the 'relu' activation -- 'elu', 'selu', and 'swish', among others -- all of which you can use in Keras. Sometimes one activation will perform better than another on a given task, so you could consider experimenting with activations as you develop a model. The ReLU activation tends to do well on most problems, so it's a good one to start with.\n\nLet's look at the graphs of some of these. Change the activation from 'relu' to one of the others named above. Then run the cell to see the graph. (Check out the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/activations) for more ideas.)","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n    layers.Dense(units=512,activation='relu', input_shape=input_shape),\n    layers.Dense(units=512,activation='relu'),\n    layers.Dense(units=512,activation='relu'),\n    layers.Dense(units=1)\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nactivation_layer = layers.Activation('sigmoid') # sigmoid, relu, elu, selu\n\nx = tf.linspace(-3.0, 3.0, 100)\ny = activation_layer(x) # once created, a layer is callable just like a function\n\nplt.figure(dpi=100)\nplt.plot(x, y)\nplt.xlim(-3, 3)\nplt.xlabel(\"Input\")\nplt.ylabel(\"Output\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-07T07:04:12.620390Z","iopub.execute_input":"2023-11-07T07:04:12.621288Z","iopub.status.idle":"2023-11-07T07:04:12.900262Z","shell.execute_reply.started":"2023-11-07T07:04:12.621236Z","shell.execute_reply":"2023-11-07T07:04:12.898883Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"#### More layers\nThere's more to the world of deep learning than just dense layers. There are dozens of kinds of layers you might add to a model. ([Keras docs](https://www.tensorflow.org/api_docs/python/tf/keras/layers/)) Some are like dense layers and define connections between neurons, and others can do preprocessing or transformations of other sorts.","metadata":{}},{"cell_type":"markdown","source":"**Dropout layer**\n\ndropout layer, can help correct overfitting.\noverfitting is caused by the network learning spurious patterns in the training data. To recognize these spurious patterns a network will often rely on very a specific combinations of weight, a kind of \"conspiracy\" of weights. Being so specific, they tend to be fragile: remove one and the conspiracy falls apart. To break up these conspiracies, we randomly drop out some fraction of a layer's input units every step of training, making it much harder for the network to learn those spurious patterns in the training data. Instead, it has to search for broad, general patterns, whose weight patterns tend to be more robust.\n\nIn keras the dropout rate argument defines what percentage of the input units to shut off. Put the Dropout layer just before the layer you want the dropout applied to.","metadata":{}},{"cell_type":"code","source":"keras.Sequential([\n    layers.Dropout(rate=0.3), # apply 30% dropout to the next layer\n    layers.Dense(16),\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Batch Normalization layer**\n\nbatch normalization (or \"batchnorm\"), can help correct training that is slow or unstable.\n\nWith neural networks, it's generally a good idea to put all of your data on a common scale, perhaps with something like scikit-learn's StandardScaler or MinMaxScaler. The reason is that SGD will shift the network weights in proportion to how large an activation the data produces. Features that tend to produce activations of very different sizes can make for unstable training behavior.\n\nA batch normalization layer looks at each batch as it comes in, first normalizing the batch with its own mean and standard deviation, and then also putting the data on a new scale with two trainable rescaling parameters. Batchnorm, in effect, performs a kind of coordinated rescaling of its inputs.\n\nMost often, batchnorm is added as an aid to the optimization process (though it can sometimes also help prediction performance). Models with batchnorm tend to need fewer epochs to complete training. Moreover, batchnorm can also fix various problems that can cause the training to get \"stuck\". Consider adding batch normalization to your models, especially if you're having trouble during training.\n\nt seems that batch normalization can be used at almost any point in a network. If you add it as the first layer of your network it can act as a kind of adaptive preprocessor, standing in for something like Sci-Kit Learn's StandardScaler.","metadata":{}},{"cell_type":"code","source":"# You can put it after a layer\nlayers.Dense(16, activation='relu'),\nlayers.BatchNormalization(),","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# between a layer and its activation function:\nlayers.Dense(16),\nlayers.BatchNormalization(),\nlayers.Activation('relu'),","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compiling model with optimizer and loss function","metadata":{}},{"cell_type":"markdown","source":"#### Loss function\n\nThe loss function measures the disparity between the the target's true value and the value the model predicts. \n\nA common loss function for regression problems is the **mean absolute error** or MAE. For each prediction y_pred, MAE measures the disparity from the true target y_true by an absolute difference abs(y_true - y_pred). The total MAE loss on a dataset is the mean of all these absolute differences.\n\nAnother popular loss function is **mean-squared error (MSE)** or the Huber loss (both available in Keras).\n\n","metadata":{}},{"cell_type":"markdown","source":"#### Optimizer - Stochastic Gradient Descent\n\nThe optimizer is an algorithm that adjusts the weights to minimize the loss.\n\n\nVirtually all of the optimization algorithms used in deep learning belong to a family called stochastic gradient descent. They are iterative algorithms that train a network in steps. One step of training goes like this:\n\n1. Sample some training data and run it through the network to make predictions.\n2. Measure the loss between the predictions and the true values.\n2. Finally, adjust the weights in a direction that makes the loss smaller.\n\nThen just do this over and over until the loss is as small as you like (or until it won't decrease any further.)\n\n**adam optimizer**:\n\nIn most ml models we use \"adam\" optimizer and its work well. Adam is an SGD algorithm that has an adaptive learning rate that makes it suitable for most problems without any parameter tuning (it is \"self tuning\", in a sense). Adam is a great general-purpose optimizer.","metadata":{}},{"cell_type":"code","source":"model.compile(\n    optimizer=\"adam\",\n    loss=\"mae\",\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Epoch and batch\n\nEach iteration's sample of training data is called a minibatch (or often just \"batch\"), while a complete round of the training data is called an epoch. The number of epochs you train for is how many times the network will see each training example.","metadata":{}},{"cell_type":"markdown","source":"#### Learning Rate and Batch Size\nNotice that the line only makes a small shift in the direction of each batch (instead of moving all the way). The size of these shifts is determined by the learning rate. A smaller learning rate means the network needs to see more minibatches before its weights converge to their best values.\n\nThe learning rate and the size of the minibatches are the two parameters that have the largest effect on how the SGD training proceeds. Their interaction is often subtle and the right choice for these parameters isn't always obvious. (We'll explore these effects in the exercise.)\n\nFortunately, for most work it won't be necessary to do an extensive hyperparameter search to get satisfactory results. Adam optimizer takes care of the learning rate.","metadata":{}},{"cell_type":"markdown","source":"### Train (fit) the model\nAfter preparing the train, test data and compiling the model with loss and optimizer, we can finally train the model. \n\nHere the training data is used to train the trained model and test data is used to check the accuracy of the model. The model takes care of all these processes at once.","metadata":{}},{"cell_type":"code","source":"model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=256,\n    epochs=10,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prevent overfitting or underfitting by adjusting capacity, early stopping\n\n**Signal and noise**\n\nThe signal is the part that generalizes, the part that can help our model make predictions from new data. The noise is that part that is only true of the training data; the noise is all of the random fluctuation that comes from data in the real-world or all of the incidental, non-informative patterns that can't actually help the model make predictions. The noise is the part might look useful but really isn't.\n\n**Overfitting and underfitting**\n\nIdeally, we would create models that learn all of the signal and none of the noise. This will practically never happen. Instead we make a trade. We can get the model to learn more signal at the cost of learning more noise. So long as the trade is in our favor, the validation loss will continue to decrease. After a certain point, however, the trade can turn against us, the cost exceeds the benefit, and the validation loss begins to rise.\n\nThis trade-off indicates that there can be two problems that occur when training a model: not enough signal or too much noise. Underfitting the training set is when the loss is not as low as it could be because the model hasn't learned enough signal. Overfitting the training set is when the loss is not as low as it could be because the model learned too much noise. The trick to training deep learning models is finding the best balance between the two.","metadata":{}},{"cell_type":"markdown","source":"**Capacity of a model**\n\nA model's capacity refers to the size and complexity of the patterns it is able to learn. For neural networks, this will largely be determined by how many neurons it has and how they are connected together. If it appears that your network is underfitting the data, you should try increasing its capacity.\n\ncapacity can be increased by making the network wider (more units to existing layers) or by making it deeper (adding more layers). Wider networks have an easier time learning more linear relationships, while deeper networks prefer more nonlinear ones. Which is better just depends on the dataset.","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n    layers.Dense(16, activation='relu'),\n    layers.Dense(1),\n])\n\nwider = keras.Sequential([\n    layers.Dense(32, activation='relu'),\n    layers.Dense(1),\n])\n\ndeeper = keras.Sequential([\n    layers.Dense(16, activation='relu'),\n    layers.Dense(16, activation='relu'),\n    layers.Dense(1),\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Early stopping\n\nwhen a model is too eagerly learning noise, the validation loss may start to increase during training. To prevent this, we can simply stop the training whenever it seems the validation loss isn't decreasing anymore. Interrupting the training this way is called early stopping. Once we detect that the validation loss is starting to rise again, we can reset the weights back to where the minimum occured. This ensures that the model won't continue to learn noise and overfit the data.\n\nKeras has a variety of useful [callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks) pre-defined, we can [define](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LambdaCallback) our own, too.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import callbacks\n\n# define early stopping callback\n## by including restore_best_weights we still get to keep the model where validation loss was lowest.\nearly_stopping = EarlyStopping(\n    min_delta=0.001, # minimium amount of change to count as an improvement\n    patience=20, # how many epochs to wait before stopping\n    restore_best_weights=True,\n)\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=512,\n    epochs=50,\n    callbacks=[early_stopping],# put your callbacks in a list as there can be multiple callbacks\n    verbose=0,  # turn off training log\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Operations","metadata":{}},{"cell_type":"markdown","source":"#### View weights\n\nA model's weights are kept in its weights attribute as a list of tensors. Before the model is trained, the weights are set to random numbers (and the bias to 0.0). A neural network learns by finding better values for its weights.","metadata":{}},{"cell_type":"code","source":"w,b = model.weights\nprint(f\"Weights\\n{w} \\n\\nBias\\n{b}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:16:05.433117Z","iopub.execute_input":"2023-11-06T18:16:05.433519Z","iopub.status.idle":"2023-11-06T18:16:05.441755Z","shell.execute_reply.started":"2023-11-06T18:16:05.433490Z","shell.execute_reply":"2023-11-06T18:16:05.440414Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Weights\n<tf.Variable 'dense/kernel:0' shape=(10, 1) dtype=float32, numpy=\narray([[ 0.16302544],\n       [-0.34366184],\n       [-0.18679059],\n       [ 0.22362942],\n       [ 0.20699704],\n       [-0.57506025],\n       [-0.63649076],\n       [ 0.513848  ],\n       [ 0.7078214 ],\n       [ 0.65834576]], dtype=float32)> \n\nBias\n<tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### History object\n\nThe fit method in fact keeps a record of the loss produced during training in a History object. \n\nWe can convert the data to a Pandas dataframe, which makes the plotting easy.","metadata":{}},{"cell_type":"code","source":"# convert the training history to a dataframe\nhistory_df = pd.DataFrame(history.history)\n\n# use Pandas native plot method\nhistory_df['loss'].plot();\n\n# Start the plot at epoch 5. You can change this to get a different view.\nhistory_df.loc[5:, ['loss']].plot();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Binary classification using tensorflow keras\n\nIt is used to classify objects in two category like, 0,1 yes,no dog,cat etc.\n\n**Accuracy**\n\nAccuracy is one of the many metrics in use for measuring success on a classification problem. Accuracy is the ratio of correct predictions to total predictions: accuracy = number_correct / total. A model that always predicted correctly would have an accuracy score of 1.0. accuracy is a reasonable metric to use whenever the classes in the dataset occur with about the same frequency.\n\nThe problem with accuracy (and most other classification metrics) is that it can't be used as a loss function. SGD needs a loss function that changes smoothly, but accuracy, being a ratio of counts, changes in \"jumps\". So, we have to choose a substitute to act as the loss function. This substitute is the cross-entropy function.\n\n**Cross-Entropy**\n\nFor classification what we need is distance between probabilities, and this is what cross-entropy provides. Cross-entropy is a sort of measure for the distance from one probability distribution to another.\n\nThe idea is that we want our network to predict the correct class with probability 1.0. The further away the predicted probability is from 1.0, the greater will be the cross-entropy loss.\n\nThe technical reasons we use cross-entropy are a bit subtle, but the main thing to take away from this section is just this: use cross-entropy for a classification loss; other metrics you might care about (like accuracy) will tend to improve along with it.\n\n**Sigmoid activation**\n\nThe cross-entropy and accuracy functions both require probabilities as inputs, meaning, numbers from 0 to 1. To covert the real-valued outputs produced by a dense layer into probabilities, we attach a new kind of activation function, the sigmoid activation.\n\n\n```python\nmodel = keras.Sequential([\n    layers.Dense(4, activation='relu', input_shape=[33]),\n    layers.Dense(4, activation='relu'),    \n    layers.Dense(1, activation='sigmoid'),\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)\n```","metadata":{}},{"cell_type":"markdown","source":"# Examples","metadata":{}},{"cell_type":"markdown","source":"## Housing price prediction model using scikit learn (Decision tree and random forest)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-11-06T17:28:09.972932Z","iopub.execute_input":"2023-11-06T17:28:09.973348Z","iopub.status.idle":"2023-11-06T17:28:10.628514Z","shell.execute_reply.started":"2023-11-06T17:28:09.973317Z","shell.execute_reply":"2023-11-06T17:28:10.627535Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"RandomForestRegressor(random_state=1)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=1)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Prepare data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/housing-prices-kaggle-learn-dataset/train.csv')\n\nfeature_columns=[\"LotArea\",\"YearBuilt\",\"1stFlrSF\",\"2ndFlrSF\",\"FullBath\",\"BedroomAbvGr\",\"TotRmsAbvGrd\"]\ntarget_column='SalePrice'\n\nX = train_df[feature_columns]\ny = train_df[target_column]\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, random_state=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define and train the model","metadata":{}},{"cell_type":"code","source":"# Define the model.\nhousing_model = DecisionTreeRegressor(random_state=1)\n#housing_model = RandomForestRegressor(random_state=1)\n\nhousing_model.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Make prediction","metadata":{}},{"cell_type":"code","source":"predicted_train = housing_model.predict(X_train)\npredicted_test = housing_model.predict(X_test)\n\n# prediction on training data\nprint(predicted_train[:5])\nprint(y_train[:5])\n\n# prediction on testing data\nprint(predicted_test[:5])\nprint(y_test[:5])","metadata":{"execution":{"iopub.status.busy":"2023-11-06T17:28:26.083327Z","iopub.execute_input":"2023-11-06T17:28:26.084369Z","iopub.status.idle":"2023-11-06T17:28:26.133793Z","shell.execute_reply.started":"2023-11-06T17:28:26.084327Z","shell.execute_reply":"2023-11-06T17:28:26.132650Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[285165.02 185861.5  149916.53 161734.   146818.59]\n6       307000\n807     223500\n955     145000\n1040    155000\n701     140000\nName: SalePrice, dtype: int64\n[187439.65 149083.25 129767.58  85257.   149803.09]\n258     231500\n267     179500\n288     122000\n649      84500\n1233    142000\nName: SalePrice, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We can see prediction on training data is almost accurate but prediction on tesing data is not exactly accurate but values are close.\n\nThis is because the model has learned based on training data and it has already seen it so it can predict it accurately, but it has not seen the testing data so values are close but not exact.","metadata":{}},{"cell_type":"markdown","source":"### Calculating Validation error","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n\ntrain_mae = mean_absolute_error(y_train, predicted_train)\ntest_mae = mean_absolute_error(y_test, predicted_test)\n\nprint(f\"mean absolute error on train data: {train_mae}, test data: {test_mae}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-06T17:28:37.951403Z","iopub.execute_input":"2023-11-06T17:28:37.952152Z","iopub.status.idle":"2023-11-06T17:28:37.960590Z","shell.execute_reply.started":"2023-11-06T17:28:37.952116Z","shell.execute_reply":"2023-11-06T17:28:37.959305Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"mean absolute error on train data: 8583.65484627093, test data: 21857.15912981083\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}